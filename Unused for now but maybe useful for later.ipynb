{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused for now but maybe useful for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apparently there is a Latex magic function in Jupyter Notebook - Cool!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\frac{\\sum_{i=1}^{n=256} \\bar{U_i}}{\\sum_{i=1}^{n=256} c_i\\bar{U_i}} \\ge \\alpha\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{n=256} \\bar{U_i}}{\\sum_{i=1}^{n=256} c_i\\bar{U_i}} \\ge \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all nominal columns from dtype Object to dtype category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nominal_columns_to_categorical():\n",
    "    object_type_columns = raw_data.dtypes.values == 'O'\n",
    "    category_df = raw_data.loc[:, object_type_columns]\n",
    "    \n",
    "    for column in category_df.columns:\n",
    "        category_df.loc[:, column] = category_df[column].astype('category')\n",
    "\n",
    "    categories = []\n",
    "    for column in category_df.columns:\n",
    "        c = category_df.loc[:, column].cat.categories\n",
    "        categories.extend(c.values)\n",
    "\n",
    "    return categories, category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories, category_df = nominal_columns_to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical to integer using Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder.fit(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in category.columns:\n",
    "    category_df.loc[:, column] = category_df.loc[:, column].map(lambda x : label_encoder.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function plots 2 histograms against the savings\n",
    "def create_histograms_by_savings(df, column, xlabel, xlim, ylim, bins):\n",
    "    ax0, ax1 = df.hist(column=column, by='savings', figsize=(14,2.5), \n",
    "                       bins=bins, alpha=0.7, xlabelsize=16, ylabelsize=16);\n",
    "    for ax in [ax0, ax1]:\n",
    "        ax.set_xlabel(xlabel, fontsize=20);\n",
    "        ax.set_ylabel('Count', fontsize=20)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlim(xlim)\n",
    "    \n",
    "    ax0.set_title('Savings < 50,000', fontsize=24);\n",
    "    ax1.set_title('Savings > 50,000', fontsize=24);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up all nominal columns into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nominal_columns_to_dummy():\n",
    "    nominal_columns = [c[0] for c in columns if c[1] == 'nominal']\n",
    "    dummy_prefix = [c[2] for c in columns if c[1] == 'nominal']\n",
    "    \n",
    "    dummy_columns = [pd.get_dummies(raw_data[col], prefix=pref) for col, pref in zip(nominal_columns, dummy_prefix)]\n",
    "    \n",
    "    data = pd.concat(dummy_columns, axis=1)\n",
    "    print 'the number of columns is {:d}'.format(data.shape[1])\n",
    "    \n",
    "    # check size\n",
    "    count_distinct_values = 0\n",
    "    for column in nominal_columns:\n",
    "        count_distinct_values += len(raw_data[column].unique())\n",
    "    \n",
    "    assert count_distinct_values == data.shape[1], \"mismatch between number of dummy columns and unique values\"\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = nominal_columns_to_dummy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Importance from Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate cross-validation data set\n",
    "class RandomForest(object):\n",
    "    \n",
    "    def __init__(self, X, y, description=''):\n",
    "        \n",
    "        self.description = description\n",
    "        print '\\n*** {:s} ***\\n'.format(self.description)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "        \n",
    "        print 'size of training data: {:7d}, {:3d}'.format(self.X_train.shape[0], self.X_train.shape[1])\n",
    "        print 'size of test data:     {:7d}, {:3d}'.format(self.X_test.shape[0], self.X_test.shape[1])\n",
    "        \n",
    "        self.rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "        self.rf_clf.fit(self.X_train.values, self.y_train.values)\n",
    "        \n",
    "        self.y_pred = self.rf_clf.predict(self.X_test)\n",
    "        self.accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        print 'accuracy = {:.4f}'.format(self.accuracy)\n",
    "        print 'class imbalance'\n",
    "        n_test = self.y_test.shape[0]\n",
    "        n_test_class = self.y_test.sum()\n",
    "        n_train = self.y_train.shape[0]\n",
    "        n_train_class = self.y_train.sum()\n",
    "        print '\\ttest set :{:7d},{:5d} : {:.4f}'.format(n_test, n_test_class, \n",
    "                                               (n_test - n_test_class)/float(n_test)) \n",
    "        print '\\ttrain set:{:7d},{:5d} : {:.4f}'.format(n_train, n_train_class, \n",
    "                                               (n_train - n_train_class)/float(n_train))\n",
    "        self.importances = self.rf_clf.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y0 = data.loc[:,'savings']\n",
    "X0 = data.drop('savings', axis=1)\n",
    "rf = RandomForest(X0, y0, 'basic setup, all columns, no feature engineering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_strong_correlations(threshold):\n",
    "    c = corr.unstack()\n",
    "    z = c.sort_values()\n",
    "    correlated = (z > threshold) & (z < 1.0)\n",
    "    uncorrelated = (z < -threshold) & (z > -1.0)\n",
    "    correlations = z[correlated | uncorrelated].drop_duplicates()\n",
    "    return correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations = find_strong_correlations(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_correlated_columns(column):\n",
    "    result = []\n",
    "    for c,v in zip(correlations.index, correlations.values):\n",
    "        if column in c[0]:\n",
    "            result.append((c[1],v))\n",
    "        if column in c[1]:\n",
    "            result.append((c[0], v))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_correlated_columns('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = find_strong_correlations(0.70)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot correlation plot\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "cax = ax.matshow(corr, cmap=plt.cm.coolwarm);\n",
    "cbar = plt.colorbar(cax, fraction=0.046, pad=0.04);\n",
    "cbar.set_label('Correlation',size=20)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "plt.yticks(range(corr.columns.values.shape[0]), fontsize=12);\n",
    "ax.set_yticklabels(corr.columns.values);\n",
    "plt.xticks(fontsize=16);\n",
    "ax.xaxis.set_ticks_position('bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
