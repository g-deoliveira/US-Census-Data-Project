{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Model Selection and Training\n",
    "Guilherme de Oliveira <br>\n",
    "8/30/2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In Chapter 2 we will work on the classification model of the US Census data that was analyzed in Chapter 1. My biggest interest in modelling will be dealing with the class imbalance of the target variable. In particular, I am interested in the following aspects:\n",
    "<ul>\n",
    "<li> How best to assess the accuracy of the classifier. It is unlikely that accuracy will suffice, because of the [accuracy paradox](https://en.wikipedia.org/wiki/Accuracy_paradox).\n",
    "<li> What are some approaches that we can use to deal with the class imbalance? Examples include oversampling, undersampling, incorporating clustering algorithms, etc...\n",
    "</ul>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# This is a work in progress. Stay tuned for more...\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "\n",
    "def preprocessData(file_name):\n",
    "    # columns stores tuples of (column_name, continuous/nominal/target, prefix for dummy encoding)\n",
    "    the_columns  = [('age', 'continuous', 'age'), \n",
    "            ('class_of_worker', 'nominal', 'class_of_worker'), \n",
    "            ('detailed_industry_code', 'nominal', 'det_ind_code'), \n",
    "            ('detailed_occupation_code', 'nominal', 'det_occ_code'), \n",
    "            ('education', 'nominal', 'edu'), \n",
    "            ('wage_per_hour', 'continuous'), \n",
    "            ('enrolled_in_education_last_week', 'nominal', 'edu_last_week'),\n",
    "            ('marital_status', 'nominal', 'marital_status'),\n",
    "            ('major_industry_code', 'nominal', 'maj_ind_code'),\n",
    "            ('major_occupation_code', 'nominal', 'maj_ocptn_code'),\n",
    "            ('race', 'nominal', 'race'),\n",
    "            ('hispanic_origin', 'nominal', 'hisp_orgn'),\n",
    "            ('sex', 'nominal', 'sex'),\n",
    "            ('member_of_labor_union', 'nominal', 'member_of_lbr_un'), \n",
    "            ('reason_for_unemployment', 'nominal', 'reason_for_unmplymnt'),\n",
    "            ('full_or_part_time_employment_stat', 'nominal', 'ft_or_pt_emplymnt_stat'),\n",
    "            ('capital_gains', 'continuous'),\n",
    "            ('capital_losses', 'continuous'),\n",
    "            ('dividends', 'continuous'),\n",
    "            ('tax_filer', 'nominal', 'tax_filer'),\n",
    "            ('region_of_previous_residence', 'nominal', 'region_pa'),\n",
    "            ('state_of_previous_residence', 'nominal', 'state_pa'),\n",
    "            ('detailed_household_family_stat', 'nominal', 'det_hse_fam_state'),\n",
    "            ('detailed_household_summary', 'nominal', 'det_hse_summary'),\n",
    "            ('instance_weight', 'continuous'),\n",
    "            ('migration_code_change_in_msa', 'nominal', 'migr_code_msa'),\n",
    "            ('migration_code_change_in_reg', 'nominal', 'migr_code_reg'),\n",
    "            ('migration_code_move_within_reg', 'nominal', 'migr_code_move'),\n",
    "            ('live_in_this_house_1_yr_ago', 'nominal', 'live_in_house_1_yr_ago'),\n",
    "            ('migration_prev_res_in_sunbelt', 'nominal', 'migr_prev_res_sunbelt'),\n",
    "            ('num_persons_worked_for_employer', 'continuous'),\n",
    "            ('family_members_under_18', 'nominal', 'family_under_18'),\n",
    "            ('cob_father', 'nominal', 'cob_father'),\n",
    "            ('cob_mother', 'nominal', 'cob_mother'),\n",
    "            ('cob_self', 'nominal', 'cob_self'),\n",
    "            ('citizenship', 'nominal', 'citizenship'),\n",
    "            ('own_business_or_self_employed', 'nominal', 'owner_or_se'),\n",
    "            ('fill_in_questionnaire_for_veterans_admin', 'nominal', 'veterans_admin'),\n",
    "            ('veterans_benefits', 'nominal', 'veterans_benefits'),\n",
    "            ('weeks_worked_in_year', 'nominal', 'weeks_worked_in_yr'),\n",
    "            ('year', 'nominal', 'year'),\n",
    "            ('savings','target'),]\n",
    "    raw_data = pd.read_csv(file_name, names=[c[0] for c in the_columns], index_col=False)\n",
    "    original_shape = raw_data.shape\n",
    "    \n",
    "    raw_data.drop('instance_weight', axis=1, inplace=True)\n",
    "    the_columns.remove(('instance_weight', 'continuous'))\n",
    "    \n",
    "    # find the duplicate rows, keep the first one\n",
    "    duplicate_rows = raw_data.duplicated(keep='first')\n",
    "    \n",
    "    print 'number of duplicates = {:d}'.format(duplicate_rows.sum())\n",
    "    raw_data = raw_data.drop_duplicates(keep='first')\n",
    "    new_shape =  raw_data.shape\n",
    "    print 'number of duplicates removed = {:d}'.format(original_shape[0] - new_shape[0])\n",
    "    print 'original shape = {:d}, {:d}'.format(original_shape[0], original_shape[1])\n",
    "    print 'new shape = {:d}, {:d}'.format(raw_data.shape[0], raw_data.shape[1])\n",
    "    \n",
    "    # convert nominal columns (object dtype) to integer type\n",
    "    data = pd.DataFrame(raw_data.select_dtypes(include=['object']))\n",
    "    object_columns = data.columns\n",
    "    \n",
    "    for column in object_columns:\n",
    "        unique_values = data[column].unique()\n",
    "        dictionary = {key:idx for idx,key in enumerate(unique_values)}\n",
    "        data[column] = data[column].apply(lambda x : dictionary[x])\n",
    "    \n",
    "    # add nominal columns that were already in integer format \n",
    "    nominal_integer_columns = [c[0] for c in the_columns if c[1] == 'nominal' and c[0] not in data.columns]\n",
    "    data[nominal_integer_columns] = raw_data[nominal_integer_columns]\n",
    "    \n",
    "    # convert 'sex', and 'savings' columns to binary; add year column\n",
    "    data['savings'] = raw_data['savings'].map(lambda x: 1 if str(x).strip() == '50000+.' else 0)\n",
    "    data['sex'] = raw_data['sex'].map(lambda x: 1 if str(x).strip() == 'Male' else 0)\n",
    "    data['year'] = raw_data['year']\n",
    "    \n",
    "    # add continuous columns\n",
    "    continuous_columns = [c[0] for c in the_columns if c[1] == 'continuous']\n",
    "    data[continuous_columns] = raw_data[continuous_columns]\n",
    "    \n",
    "    # verify that we aren't missing any columns\n",
    "    assert set(data.columns) == (set(raw_data.columns))\n",
    "\n",
    "    print 'The final processed data has {:,d} rows and {:d} columns.\\n'.format(data.shape[0], data.shape[1])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates = 46627\n",
      "number of duplicates removed = 46627\n",
      "original shape = 199523, 42\n",
      "new shape = 152896, 41\n",
      "The final processed data has 152,896 rows and 41 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = preprocessData('us_census_full/census_income_learn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_of_worker</th>\n",
       "      <th>education</th>\n",
       "      <th>enrolled_in_education_last_week</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>major_industry_code</th>\n",
       "      <th>major_occupation_code</th>\n",
       "      <th>race</th>\n",
       "      <th>hispanic_origin</th>\n",
       "      <th>sex</th>\n",
       "      <th>member_of_labor_union</th>\n",
       "      <th>...</th>\n",
       "      <th>own_business_or_self_employed</th>\n",
       "      <th>veterans_benefits</th>\n",
       "      <th>weeks_worked_in_year</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>capital_gains</th>\n",
       "      <th>capital_losses</th>\n",
       "      <th>dividends</th>\n",
       "      <th>num_persons_worked_for_employer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_of_worker  education  enrolled_in_education_last_week  \\\n",
       "0                0          0                                0   \n",
       "1                1          1                                0   \n",
       "2                0          2                                1   \n",
       "\n",
       "   marital_status  major_industry_code  major_occupation_code  race  \\\n",
       "0               0                    0                      0     0   \n",
       "1               1                    1                      1     0   \n",
       "2               2                    0                      0     1   \n",
       "\n",
       "   hispanic_origin  sex  member_of_labor_union  \\\n",
       "0                0    0                      0   \n",
       "1                0    1                      0   \n",
       "2                0    0                      0   \n",
       "\n",
       "                ...                 own_business_or_self_employed  \\\n",
       "0               ...                                             0   \n",
       "1               ...                                             0   \n",
       "2               ...                                             0   \n",
       "\n",
       "   veterans_benefits  weeks_worked_in_year  year  age  wage_per_hour  \\\n",
       "0                  2                     0    95   73              0   \n",
       "1                  2                    52    94   58              0   \n",
       "2                  2                     0    95   18              0   \n",
       "\n",
       "   capital_gains  capital_losses  dividends  num_persons_worked_for_employer  \n",
       "0              0               0          0                                0  \n",
       "1              0               0          0                                1  \n",
       "2              0               0          0                                0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data:  107027,  40\n",
      "size of test data:       45869,  40\n"
     ]
    }
   ],
   "source": [
    "# obtain training and test set for cross-validation\n",
    "X = data.drop('savings', axis=1)\n",
    "y = data.loc[:,'savings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print 'size of training data: {:7d}, {:3d}'.format(X_train.shape[0], X_train.shape[1])\n",
    "print 'size of test data:     {:7d}, {:3d}'.format(X_test.shape[0], X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy with 100 trees = 0.9394\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print 'Random Forest accuracy with {:d} trees = {:.4f}'.format(rf_clf.n_estimators, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy = 0.9399\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 200)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print 'Random Forest accuracy = {:.4f}'.format(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy = 0.9404\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 400)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print 'Random Forest accuracy = {:.4f}'.format(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate Some Feature Engineering\n",
    "Start with the column \"detailed_household_family_stat\" and convert the classes that have no savings greater than 50K into one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values for savings = 1 [ 0  1  2  3  4  5  6  7 10 11 12 15 16 17 18 19 22 28 30]\n",
      "unique values for all vals    [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37]\n",
      " the differences are........ set([32, 33, 34, 35, 36, 37, 8, 9, 13, 14, 20, 21, 23, 24, 25, 26, 27, 29, 31])\n",
      " len(diff) 19\n",
      " mapping values to: 38\n"
     ]
    }
   ],
   "source": [
    "dhfs = data['detailed_household_family_stat'][data['savings'] == 1].unique()\n",
    "dhfs.sort()\n",
    "print 'unique values for savings = 1', dhfs\n",
    "dhfs_all = data['detailed_household_family_stat'].unique()\n",
    "dhfs_all.sort()\n",
    "print 'unique values for all vals   ', dhfs_all\n",
    "\n",
    "diff = set(dhfs_all).difference(set(dhfs))\n",
    "print ' the differences are........', diff\n",
    "if diff is None:\n",
    "    print '\\n diff is empty'\n",
    "else:\n",
    "    print ' len(diff)', len(diff)\n",
    "    val = max(diff) + 1\n",
    "    print ' mapping values to:', val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_column(column):\n",
    "    dhfs = data[column][data['savings'] == 1].unique()\n",
    "    dhfs.sort()\n",
    "    print 'unique values for svngs = 1', dhfs\n",
    "    dhfs_all = data[column].unique()\n",
    "    dhfs_all.sort()\n",
    "    print 'unique values for all vals ', dhfs_all\n",
    "    \n",
    "    diff = set(dhfs_all).difference(set(dhfs))\n",
    "    print ' the differences are........', diff\n",
    "    if diff is None:\n",
    "        print '\\n diff is empty'\n",
    "        return data[column]\n",
    "    \n",
    "    print ' len(diff)', len(diff)\n",
    "    \n",
    "    val = max(diff) + 1\n",
    "    print ' mapping values to:', val\n",
    "    return data[column].map(lambda x : val if x in diff else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values for svngs = 1 [ 0  1  2  3  4  5  6  7 10 11 12 15 16 17 18 19 22 28 30]\n",
      "unique values for all vals  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37]\n",
      " the differences are........ set([32, 33, 34, 35, 36, 37, 8, 9, 13, 14, 20, 21, 23, 24, 25, 26, 27, 29, 31])\n",
      " len(diff) 19\n",
      " mapping values to: 38\n"
     ]
    }
   ],
   "source": [
    "data['detailed_household_family_stat'] = update_column('detailed_household_family_stat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values for svngs = 1 [ 0  1  2  3  4  5  6  7 10 11 12 15 16 17 18 19 22 28 30]\n",
      "unique values for all vals  [ 0  1  2  3  4  5  6  7 10 11 12 15 16 17 18 19 22 28 30 38]\n",
      " the differences are........ set([38])\n",
      " len(diff) 1\n",
      " mapping values to: 39\n"
     ]
    }
   ],
   "source": [
    "update_column('detailed_household_family_stat');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7 38 10 11 12 15 16 17 18 19 22 28 30]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print data['detailed_household_family_stat'].unique()\n",
    "print data['savings'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(data_vis): (152896, 2)\n",
      "[[-582.86880395  219.21581787]\n",
      " [-582.85729319  219.25677883]\n",
      " [-582.8777853   219.26440239]\n",
      " [-582.87925719  219.27225601]]\n",
      "[[ -582.8665234    219.20378154]\n",
      " [ 5821.79914647   633.03285533]\n",
      " [ -572.51524791    62.59966318]\n",
      " [ -582.8543837    219.28715813]]\n",
      "pca.components_.shape: (2, 40)\n",
      "pca.explained_variance_ratio_: [ 0.8470303   0.14724605]\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "data_vis = pca.fit_transform(X)\n",
    "print 'shape(data_vis):', data_vis.shape\n",
    "print data_vis[:4,:]\n",
    "print data_vis[-4:,:]\n",
    "print 'pca.components_.shape:', pca.components_.shape\n",
    "print 'pca.explained_variance_ratio_:', pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y==0 :  140529\n",
      "y==1 :  12367\n",
      "y==0 + y==1: 152896\n"
     ]
    }
   ],
   "source": [
    "print 'y==0 : ', (y==0).sum()\n",
    "print 'y==1 : ', (y==1).sum()\n",
    "print 'y==0 + y==1:', (y==0).sum() + (y==1).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the original data\n",
    "# Plot the two classes\n",
    "\n",
    "def scatter_plot(X, y):\n",
    "    data_vis = pca.fit_transform(X)\n",
    "    \n",
    "    yeq0 = data_vis[ (y==0) ]\n",
    "    yeq1 = data_vis[ (y==1) ]\n",
    "    \n",
    "    palette = sns.color_palette()\n",
    "    almost_black = '#262626'\n",
    "    \n",
    "    fig=plt.figure(figsize=(9,9));\n",
    "    ax = fig.gca();\n",
    "    ax.scatter(yeq0[:, 0], yeq0[:, 1], label=\"Savings < 50K\", alpha=0.3, facecolor=palette[0], \n",
    "               linewidth=0.15, edgecolor=almost_black);\n",
    "    ax.scatter(yeq1[:, 0], yeq1[:, 1], label=\"Savings > 50K\", alpha=0.3, facecolor=palette[2], \n",
    "               linewidth=0.15, edgecolor=almost_black);\n",
    "    ax.legend(fontsize=16, loc='lower left', bbox_to_anchor=(1,0.8));\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = scatter_plot(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "#from imblearn.under_sampling import AllKNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the new dataset using under-sampling method\n",
    "verbose = False\n",
    "\n",
    "# 'Random under-sampling'\n",
    "US = RandomUnderSampler()\n",
    "usx, usy = US.fit_sample(X, y)\n",
    "ax = scatter_plot(usx, usy);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'Tomek links'\n",
    "TL = TomekLinks()\n",
    "tlx, tly = TL.fit_sample(X, y)\n",
    "ax = scatter_plot(tlx, tly);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'Clustering centroids'\n",
    "CC = ClusterCentroids()\n",
    "ccx, ccy = CC.fit_sample(X, y)\n",
    "ax = scatter_plot(ccx, ccy);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'NearMiss-1'\n",
    "NM1 = NearMiss(version=1)\n",
    "nm1x, nm1y = NM1.fit_sample(X, y)\n",
    "ax = scatter_plot(nm1x, nm1y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'NearMiss-2'\n",
    "NM2 = NearMiss(version=2)\n",
    "nm2x, nm2y = NM2.fit_sample(X, y)\n",
    "ax = scatter_plot(nm2x, nm2y);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'NearMiss-3'\n",
    "NM3 = NearMiss(version=3)\n",
    "nm3x, nm3y = NM3.fit_sample(X, y)\n",
    "ax = scatter_plot(nm3x, nm3y);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Condensed Nearest Neighbour'\n",
    "CNN = CondensedNearestNeighbour(size_ngh=51, n_seeds_S=51)\n",
    "cnnx, cnny = CNN.fit_sample(X, y)\n",
    "ax = scatter_plot(cnnx, cnny);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'One-Sided Selection'\n",
    "OSS = OneSidedSelection(size_ngh=51, n_seeds_S=51)\n",
    "ossx, ossy = OSS.fit_sample(X, y)\n",
    "ax = scatter_plot(ossx, ossy);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Neighboorhood Cleaning Rule'\n",
    "NCR = NeighbourhoodCleaningRule(size_ngh=51)\n",
    "ncrx, ncry = NCR.fit_sample(X, y) \n",
    "ax = scatter_plot(ncrx, ncry);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Edited Neareast Neighbour'\n",
    "ENN = EditedNearestNeighbours(size_ngh=51)\n",
    "ennx, enny = ENN.fit_sample(X, y)\n",
    "ax = scatter_plot(ennx, enny);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Instance Hardness Threshold'\n",
    "IHT = InstanceHardnessThreshold()\n",
    "ihtx, ihty = IHT.fit_sample(X, y)\n",
    "ax = scatter_plot(ihtx, ihty);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Repeated Edited Nearest Neighbour'\n",
    "RENN = RepeatedEditedNearestNeighbours(size_ngh=51)\n",
    "rennx, renny = RENN.fit_sample(X, y)\n",
    "ax = scatter_plot(rennx, renny);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
